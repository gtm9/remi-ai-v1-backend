## Usage Instructions
### Environment Setup
1. Download this repository:
```bash
git clone https://github.com/index-tts/index-tts.git
```
2. Install dependencies:

Create a new conda environment and install dependencies:
 
```bash
conda create -n index-tts python=3.10
conda activate index-tts
apt-get install ffmpeg
# or use conda to install ffmpeg
conda install -c conda-forge ffmpeg
```

Install [PyTorch](https://pytorch.org/get-started/locally/), e.g.:
```bash
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118
```

> [!NOTE]
> If you are using Windows you may encounter [an error](https://github.com/index-tts/index-tts/issues/61) when installing `pynini`:
`ERROR: Failed building wheel for pynini`
> In this case, please install `pynini` via `conda`:
> ```bash
> # after conda activate index-tts
> conda install -c conda-forge pynini==2.1.6
> pip install WeTextProcessing --no-deps
> ```

Install `IndexTTS` as a package:
```bash
cd index-tts
pip install -e .
```

3. Download models:

Download by `huggingface-cli`:

```bash
huggingface-cli download IndexTeam/IndexTTS-1.5 \
  config.yaml bigvgan_discriminator.pth bigvgan_generator.pth bpe.model dvae.pth gpt.pth unigram_12000.vocab \
  --local-dir checkpoints
```

Recommended for China users. å¦‚æœä¸‹è½½é€Ÿåº¦æ…¢ï¼Œå¯ä»¥ä½¿ç”¨é•œåƒï¼š
```bash
export HF_ENDPOINT="https://hf-mirror.com"
```

Or by `wget`:

```bash
wget https://huggingface.co/IndexTeam/IndexTTS-1.5/resolve/main/bigvgan_discriminator.pth -P checkpoints
wget https://huggingface.co/IndexTeam/IndexTTS-1.5/resolve/main/bigvgan_generator.pth -P checkpoints
wget https://huggingface.co/IndexTeam/IndexTTS-1.5/resolve/main/bpe.model -P checkpoints
wget https://huggingface.co/IndexTeam/IndexTTS-1.5/resolve/main/dvae.pth -P checkpoints
wget https://huggingface.co/IndexTeam/IndexTTS-1.5/resolve/main/gpt.pth -P checkpoints
wget https://huggingface.co/IndexTeam/IndexTTS-1.5/resolve/main/unigram_12000.vocab -P checkpoints
wget https://huggingface.co/IndexTeam/IndexTTS-1.5/resolve/main/config.yaml -P checkpoints
```

> [!NOTE]
> If you prefer to use the `IndexTTS-1.0` model, please replace `IndexTeam/IndexTTS-1.5` with `IndexTeam/IndexTTS` in the above commands.


4. Run test script:


```bash
# Please put your prompt audio in 'test_data' and rename it to 'input.wav'
python indextts/infer.py
```

5. Use as command line tool:

```bash
# Make sure pytorch has been installed before running this command
indextts "å¤§å®¶å¥½ï¼Œæˆ‘ç°åœ¨æ­£åœ¨bilibili ä½“éªŒ ai ç§‘æŠ€ï¼Œè¯´å®è¯ï¼Œæ¥ä¹‹å‰æˆ‘ç»å¯¹æƒ³ä¸åˆ°ï¼AIæŠ€æœ¯å·²ç»å‘å±•åˆ°è¿™æ ·åŒªå¤·æ‰€æ€çš„åœ°æ­¥äº†ï¼" \
  --voice reference_voice.wav \
  --model_dir checkpoints \
  --config checkpoints/config.yaml \
  --output output.wav
```

Use `--help` to see more options.
```bash
indextts --help
```

#### Web Demo
```bash
pip install -e ".[webui]" --no-build-isolation
python webui.py

# use another model version:
python webui.py --model_dir IndexTTS-1.5
```

Open your browser and visit `http://127.0.0.1:7860` to see the demo.


#### Sample Code
```python
from indextts.infer import IndexTTS
tts = IndexTTS(model_dir="checkpoints",cfg_path="checkpoints/config.yaml")
voice="reference_voice.wav"
text="å¤§å®¶å¥½ï¼Œæˆ‘ç°åœ¨æ­£åœ¨bilibili ä½“éªŒ ai ç§‘æŠ€ï¼Œè¯´å®è¯ï¼Œæ¥ä¹‹å‰æˆ‘ç»å¯¹æƒ³ä¸åˆ°ï¼AIæŠ€æœ¯å·²ç»å‘å±•åˆ°è¿™æ ·åŒªå¤·æ‰€æ€çš„åœ°æ­¥äº†ï¼æ¯”å¦‚è¯´ï¼Œç°åœ¨æ­£åœ¨è¯´è¯çš„å…¶å®æ˜¯Bç«™ä¸ºæˆ‘ç°åœºå¤åˆ»çš„æ•°å­—åˆ†èº«ï¼Œç®€ç›´å°±æ˜¯å¹³è¡Œå®‡å®™çš„å¦ä¸€ä¸ªæˆ‘äº†ã€‚å¦‚æœå¤§å®¶ä¹Ÿæƒ³ä½“éªŒæ›´å¤šæ·±å…¥çš„AIGCåŠŸèƒ½ï¼Œå¯ä»¥è®¿é—® bilibili studioï¼Œç›¸ä¿¡æˆ‘ï¼Œä½ ä»¬ä¹Ÿä¼šåƒæƒŠçš„ã€‚"
tts.infer(voice, text, output_path)
```

## Acknowledge
1. [tortoise-tts](https://github.com/neonbjb/tortoise-tts)
2. [XTTSv2](https://github.com/coqui-ai/TTS)
3. [BigVGAN](https://github.com/NVIDIA/BigVGAN)
4. [wenet](https://github.com/wenet-e2e/wenet/tree/main)
5. [icefall](https://github.com/k2-fsa/icefall)

## ğŸ“š Citation

ğŸŒŸ If you find our work helpful, please leave us a star and cite our paper.

```
@article{deng2025indextts,
  title={IndexTTS: An Industrial-Level Controllable and Efficient Zero-Shot Text-To-Speech System},
  author={Wei Deng, Siyi Zhou, Jingchen Shu, Jinchao Wang, Lu Wang},
  journal={arXiv preprint arXiv:2502.05512},
  year={2025}
}
```
